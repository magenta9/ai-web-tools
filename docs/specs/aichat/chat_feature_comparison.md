# AI Chat 功能差距分析 (vs T3 Chat / Modern AI Standards)

本分析对比了当前项目的 AI Chat 功能与 [T3 Chat](https://chat.t3.gg) (以及主流现代 AI 对话应用如 ChatGPT/Claude) 的主要功能差距。

## 1. 核心体验差距

| 功能特性 | T3 Chat / 业界标准 | 当前项目现状 | 差距严重程度 |
| :--- | :--- | :--- | :--- |
| **流式响应 (Streaming)** | **支持**。逐字显示响应，首字延迟 (TTFT) 极低，交互流畅。 | **不支持**。使用 `stream: false`，需等待完整响应生成后一次性返回。 | 🔴 严重 (影响体验) |
| **持久化历史 (History)** | **支持**。自动保存所有对话，支持搜索、导出、多设备同步或本地存储。 | **不支持**。刷新页面即丢失 (Chat 页面未接入通用的 `UseHistory` 系统)。 | 🔴 严重 (数据丢失) |
| **联网搜索 (Web Search)** | **支持**。可实时搜索网络信息，提供来源引用的回答 (Grounding)。 | **不支持**。仅依赖模型训练数据。 | 🟡 中等 (功能缺失) |
| **多模态/附件 (Attachments)** | **支持**。可上传图片、文档进行分析。 | **不支持**。仅支持纯文本输入。 | 🟡 中等 (场景受限) |

## 2. 交互与界面差距

| 功能特性 | T3 Chat / 业界标准 | 当前项目现状 | 差距严重程度 |
| :--- | :--- | :--- | :--- |
| **消息编辑 (Editing)** | 支持编辑已发送的用户消息并重新生成分支对话。 | 不支持。 | 🟢 低 (锦上添花) |
| **Artifacts / Preview** | 独立的代码/内容预览窗口 (如 Claude Artifacts)，支持渲染 HTML/React。 | 仅支持 Markdown 代码块语法高亮，无独立预览视图。 | 🟡 中等 (开发场景重要) |
| **快捷键优化** | 支持 `Cmd+K` 搜索、`Enter` 发送配置等全键盘操作。 | 仅支持基础的 `Enter` 发送和 `Shift+Enter` 换行。 | 🟢 低 |
| **模型切换** | 细粒度控制，支持在对话中途切换模型。 | 支持。已有 `ModelSelector` 组件。 | ✅ 已对齐 |

## 3. 架构与技术栈差距

- **后端通信**:
  - **T3 Chat**: 使用 Edge Runtime 或 WebSocket/SSE 实现流式传输。
  - **当前项目**: 标准 REST API (`POST /api/ollama/chat`) 短连接，阻塞式等待。

- **数据存储**:
  - **T3 Chat**: 通常结合 IndexedDB (本地) 或 PostgreSQL (云端) 进行完整的会话状态管理。
  - **当前项目**: 后端有 PostgreSQL 和 `tool_history` 表，但 Chat 模块未集成；前端仅使用 React State。

## 4. 改进建议 (路线图)

基于上述差距，建议按以下优先级进行迭代：

### 第一阶段：基础体验补齐 (P0)
1.  **接入历史记录**: 利用现有的 `useHistory` Hook 和后端 `/api/history` 接口，实现会话持久化。
2.  **开启流式响应**: 改造后端 `OllamaHandler` 支持 `stream: true`，前端使用 `EventSource` 或 `fetch` 流式读取。

### 第二阶段：功能增强 (P1)
1.  **增加联网能力 (Local-First)**: 使用 Playwright 或 Fetch (MCP) 实现本地网页检索，增强上下文信息，保持数据隐私。
2.  **优化代码展示**: 引入类似 Artifacts 的独立代码预览面板，提升编程辅助体验。

### 第三阶段：高级特性 (P2)
1.  **多模态支持**: 允许上传图片并透传给支持 Vision 的 Ollama 模型 (如 Llava)。
2.  **会话管理**: 增加侧边栏会话列表，支持新建/重命名/删除会话。
